{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание признаков <br>\n",
    "* Разбор числовых величин <br>\n",
    "* Разбор текста <br>\n",
    "* Разбор категорий <br>\n",
    "### Создание признаков. Внешние источники <br>\n",
    "### Создание признаков. Работа с форматом «дата-время» <br>\n",
    "### Кодирование признаков. Методы <br>\n",
    "* ПОРЯДКОВОЕ КОДИРОВАНИЕ. ORDINAL ENCODING <br>\n",
    "* ОДНОКРАТНОЕ КОДИРОВАНИЕ. ONE-HOT ENCODING <br>\n",
    "* ДВОИЧНОЕ КОДИРОВАНИЕ <br>\n",
    "### Преобразование признаков. Нормализация. Стандартизация <br>\n",
    "* Нормализация <br>\n",
    "* MINMAXSCALER <br>\n",
    "* ROBUSTSCALER <br>\n",
    "* СТАНДАРТИЗАЦИЯ  STANDARDSCALER <br>\n",
    "### Отбор признаков. Мультиколлинеарность <br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание признаков"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "РАЗБОР ЧИСЛОВЫХ ВЕЛИЧИН"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для удобства сразу преобразуем признак в int\n",
    "data['price_round'] = data['price'].round().astype(int)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "РАЗБОР ТЕКСТА"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[^@ \\t\\r\\n]+@[^@ \\t\\r\\n]+\\.[^@ \\t\\r\\n]+ можно найти любой email в тексте"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = '\\d{4}' # регулярное выражение для нахождения чисел\n",
    "data['year'] = data['title'].str.findall(regex).str.get(0)\n",
    "\n",
    "# метод .str.findall(regex) (!!!!!)\n",
    "#  извлечь первый элемент из списка найденных методом str.get(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "РАЗБОР КАТЕГОРИЙ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['is_usa'] = data['country'].apply(lambda x: 1 if x == 'US' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2\n",
    "\n",
    "data['is_france'] = data['country'].apply(lambda x: 1 if x == 'France' else 0) \n",
    "# ставим значение 1 там, где страна France\n",
    "ata['is_italy'] = data['country'].apply(lambda x: 1 if x == 'Italy' else 0) \n",
    "# ставим значение 1 там, где страна Italy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3\n",
    "\n",
    "# преобразуем признак year в объект datetime для удобного сравнения дат\n",
    "data['year'] = pd.to_datetime(data['year'], errors='coerce')\n",
    "\n",
    "# для сравнения используем год, заполняем значения признака old_wine, где год вина меньше 2010\n",
    "data['old_wine'] = data['year'].apply(lambda x: 1 if x.year < 2010 else 0) \n",
    "data['old_wine'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.7\n",
    "\n",
    "regex = '\\((.*?)\\)'\n",
    "data['locality'] = data['title'].str.findall(regex).str.get(0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание признаков. Внешние источники"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "РАБОТА С ФАЙЛАМИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "country_population = pd.read_csv('country_population.csv', sep=';')\n",
    "\n",
    "country_population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1\n",
    "\n",
    "country_population.loc[country_population['country'] == 'Italy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.join(country_population.set_index('country'), on='country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "country_area = pd.read_csv('country_area.csv', sep=';')\n",
    "country_area"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание признаков. Работа с форматом «дата-время»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "# инициализируем информацию о звонках\n",
    "calls_list = [\n",
    "    [460, '2013-12-17 04:55:39', '2013-12-17 04:55:44', '2013-12-17 04:55:45'],\n",
    "    [12, '2013-12-16 20:03:20', '2013-12-16 20:03:22', '2013-12-16 20:07:13'],\n",
    "    [56, '2013-12-16 20:03:20', '2013-12-16 20:03:20', '2013-12-16 20:05:04'],\n",
    "    [980, '2013-12-16 20:03:20','2013-12-16 20:03:27', '2013-12-16 20:03:29'],\n",
    "    [396, '2013-12-16 20:08:27', '2013-12-16 20:08:28','2013-12-16 20:12:03'],\n",
    "    [449, '2013-12-16 20:03:20', '2013-12-16 20:03:25','2013-12-16 20:05:00'],\n",
    "    [397, '2013-12-16 20:08:25', '2013-12-16 20:08:27', '2013-12-16 20:09:59'],\n",
    "    [398, '2013-12-16 20:01:23', '2013-12-16 20:01:23', '2013-12-16 20:04:58'],\n",
    "    [452, '2013-12-16 20:03:20', '2013-12-16 20:03:21','2013-12-16 20:04:55'],\n",
    "    [440, '2013-12-16 20:03:20', '2013-12-16 20:04:26', '2013-12-16 20:04:32']\n",
    "]\n",
    "\n",
    "calls = pd.DataFrame(calls_list, columns = ['client_id',  'agent_date', 'created_at' ,'end_date'])\n",
    "\n",
    "# преобразовываем признаки в формат datetime для удобной работы\n",
    "\n",
    "calls['agent_date'] = pd.to_datetime(calls['agent_date'])\n",
    "calls['created_at'] = pd.to_datetime(calls['created_at'])\n",
    "calls['end_date'] = pd.to_datetime(calls['end_date'])\n",
    "\n",
    "calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls['duration'] = (calls['end_date'] - calls['created_at']).dt.seconds\n",
    "calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1\n",
    "\n",
    "calls['time_connection'] = (calls['created_at'] - calls['agent_date']).dt.seconds\n",
    "calls['time_connection'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2\n",
    "\n",
    "calls['is_connection'] = calls['duration'].apply(lambda x: 1 if x> 10 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3\n",
    "\n",
    "calls['time_diff'] = (calls['end_date'] - calls['agent_date']).dt.seconds\n",
    "calls['time_diff'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calls = calls.drop(columns=['agent_date', 'created_at' ,'end_date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.5\n",
    "\n",
    "data['year'] = pd.to_datetime(data['year'], errors = 'coerce')\n",
    "data['years_diff'] = (pd.to_datetime(\"2022-01-12\") - data['year']).dt.days\n",
    "data['years_diff'].max()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кодирование признаков. Методы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# инициализируем информацию об одежде\n",
    "clothing_list = [\n",
    "    ['xxs', 'dress'],\n",
    "    ['xxs', 'skirt'],\n",
    "    ['xs', 'dress'],\n",
    "    ['s', 'skirt'],\n",
    "    ['m', 'dress'],\n",
    "    ['l', 'shirt'],\n",
    "    ['s', 'coat'],\n",
    "    ['m', 'coat'],\n",
    "    ['xxl', 'shirt'],\n",
    "    ['l', 'dress']\n",
    "]\n",
    "\n",
    "clothing = pd.DataFrame(clothing_list, columns = ['size',  'type'])\n",
    "clothing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ПОРЯДКОВОЕ КОДИРОВАНИЕ. ORDINAL ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce # импортируем библиотеку для работы с кодировщиками\n",
    "\n",
    "ord_encoder = ce.OrdinalEncoder()\n",
    "data_bin = ord_encoder.fit_transform(clothing[['size']])\n",
    "clothing = pd.concat([clothing, data_bin], axis=1)\n",
    "\n",
    "clothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "ord_encoder = ce.OrdinalEncoder(cols=['year'])\n",
    "year_col = ord_encoder.fit_transform(wine_cleared['year'])\n",
    "data = pd.concat([wine_cleared, year_col], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ОДНОКРАТНОЕ КОДИРОВАНИЕ. ONE-HOT ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce # импорт для работы с кодировщиком\n",
    "\n",
    "encoder = ce.OneHotEncoder(cols=['type'], use_cat_names=True) # указываем столбец для кодирования\n",
    "type_bin = encoder.fit_transform(clothing['type'])\n",
    "clothing = pd.concat([clothing, type_bin], axis=1)\n",
    "\n",
    "clothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_dummies = pd.get_dummies(clothing, columns=['type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.4\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "encoder = ce.OneHotEncoder(cols=['taster_name'])\n",
    "type_bin = encoder.fit_transform(data['taster_name'])\n",
    "data = pd.concat([data, type_bin], axis=1)\n",
    "\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ДВОИЧНОЕ КОДИРОВАНИЕ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import category_encoders as ce # импорт для работы с кодировщиком\n",
    "bin_encoder = ce.BinaryEncoder(cols=['type']) # указываем столбец для кодирования\n",
    "type_bin = bin_encoder.fit_transform(clothing['type'])\n",
    "clothing = pd.concat([clothing, type_bin], axis=1)\n",
    "\n",
    "clothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.5\n",
    "\n",
    "bin_encoder = ce.BinaryEncoder(cols=['country'])\n",
    "country_bin = bin_encoder.fit_transform(data['country'])\n",
    "data = pd.concat([data, country_bin], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.8\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "encoder = ce.BinaryEncoder(cols=['taster_twitter_handle'])\n",
    "type_bin = encoder.fit_transform(data['taster_twitter_handle'])\n",
    "data = pd.concat([data, type_bin], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.9\n",
    "\n",
    "import category_encoders as ce\n",
    "\n",
    "encoder = ce.OneHotEncoder(cols=['product','payment_type'])\n",
    "cols = encoder.fit_transform(df[['product','payment_type']])\n",
    "df = pd.concat([df, cols], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Преобразование признаков. Нормализация. Стандартизация"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "НОРМАЛИЗАЦИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(34)\n",
    "\n",
    "# для нормализации, стандартизации\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Для графиков\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "# сгенерируем датасет из случайных чисел\n",
    "df = pd.DataFrame({ \n",
    "    # Бета распределение, 5 – значение альфа, 1 – значение бета, 1000 – размер\n",
    "    'beta': np.random.beta(5, 1, 1000) * 60,\n",
    "    \n",
    "    # Экспоненциальное распределение, 10 – \"резкость\" экспоненты, 1000 – размер\n",
    "    'exponential': np.random.exponential(10, 1000),\n",
    "    \n",
    "    # Нормальное распределение, 10 – среднее значение р., 2 – стандартное отклонение, 1000 – количество сэмплов\n",
    "    'normal_p': np.random.normal(10, 2, 1000),\n",
    "    \n",
    "    # Нормальное распределение, 10 – среднее значение р., 10 – стандартное отклонение, 1000 – количество сэмплов\n",
    "    'normal_l': np.random.normal(10, 10, 1000),\n",
    "})\n",
    "\n",
    "# Копируем названия столбцов, которые теряются при использовании fit_transform()\n",
    "col_names = list(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# зададим параметры холста, название и визуализируем кривые распределения:\n",
    "fig, (ax1) = plt.subplots(ncols=1, figsize=(10, 8))\n",
    "ax1.set_title('Исходные распределения')\n",
    "\n",
    "# kdeplot() (KDE – оценка плотности ядра) – специальный метод для графиков распределений\n",
    "sns.kdeplot(df['beta'], ax=ax1, label ='beta')\n",
    "sns.kdeplot(df['exponential'], ax=ax1, label ='exponential')\n",
    "sns.kdeplot(df['normal_p'], ax=ax1, label ='normal_p')\n",
    "sns.kdeplot(df['normal_l'], ax=ax1, label ='normal_l')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MINMAXSCALER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем нормализатор MinMaxScaler\n",
    "mm_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# кодируем исходный датасет\n",
    "df_mm = mm_scaler.fit_transform(df)\n",
    "\n",
    "# Преобразуем промежуточный датасет в полноценный датафрейм для визуализации\n",
    "df_mm = pd.DataFrame(df_mm, columns=col_names)\n",
    "\n",
    "fig, (ax1) = plt.subplots(ncols=1, figsize=(10, 8))\n",
    "ax1.set_title('После нормализации MinMaxScaler')\n",
    "\n",
    "sns.kdeplot(df_mm['beta'], ax=ax1)\n",
    "sns.kdeplot(df_mm['exponential'], ax=ax1)\n",
    "sns.kdeplot(df_mm['normal_p'], ax=ax1)\n",
    "sns.kdeplot(df_mm['normal_l'], ax=ax1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROBUSTSCALER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем нормализатор RobustScaler\n",
    "r_scaler = preprocessing.RobustScaler()\n",
    "\n",
    "# кодируем исходный датасет\n",
    "df_r = r_scaler.fit_transform(df)\n",
    "\n",
    "# Преобразуем промежуточный датасет в полноценный датафрейм для визуализации\n",
    "df_r = pd.DataFrame(df_r, columns=col_names)\n",
    "\n",
    "fig, (ax1) = plt.subplots(ncols=1, figsize=(10, 8))\n",
    "ax1.set_title('Распределения после RobustScaler')\n",
    "\n",
    "sns.kdeplot(df_r['beta'], ax=ax1)\n",
    "sns.kdeplot(df_r['exponential'], ax=ax1)\n",
    "sns.kdeplot(df_r['normal_p'], ax=ax1)\n",
    "sns.kdeplot(df_r['normal_l'], ax=ax1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "СТАНДАРТИЗАЦИЯ  STANDARDSCALER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем стандартизатор StandardScaler\n",
    "s_scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# кодируем исходный датасет\n",
    "df_s = s_scaler.fit_transform(df)\n",
    "\n",
    "# Преобразуем промежуточный датасет в полноценный датафрейм для визуализации\n",
    "df_s = pd.DataFrame(df_s, columns=col_names)\n",
    "\n",
    "fig, (ax1) = plt.subplots(ncols=1, figsize=(10, 8))\n",
    "ax1.set_title('Распределения после StandardScaler')\n",
    "\n",
    "sns.kdeplot(df_s['beta'], ax=ax1)\n",
    "sns.kdeplot(df_s['exponential'], ax=ax1)\n",
    "sns.kdeplot(df_s['normal_p'], ax=ax1)\n",
    "sns.kdeplot(df_s['normal_l'], ax=ax1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Отбор признаков. Мультиколлинеарность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris = pd.read_csv('iris.csv')\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns # импортируем seaborn для построения графиков\n",
    "sns.heatmap(iris.corr(), annot=True) # включаем отображение коэффициентов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = iris.drop(['petal.width'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = iris.drop(['petal.length'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.4\n",
    "\n",
    "# Построим график корреляции всех величин. Для простоты воспользуемся корреляцией Пирсона.\n",
    "\n",
    "# работа с визуализацией\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "sns.heatmap(data.corr(), annot=True, linewidths=.5, ax=ax)\n",
    "\n",
    "# Удалим самые сильно скоррелированные пары\n",
    "data = data.drop(['is_usa', 'is_france', 'is_italy', 'price_round', 'area'], axis=1)\n",
    "\n",
    "# Проверяем, что сильно скоррелированных признаков не осталось\n",
    "sns.heatmap(data.corr(), annot=True, linewidths=.5, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.6\n",
    "\n",
    "# для нормализации, стандартизации\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# инициализируем нормализатор RobustScaler\n",
    "r_scaler = preprocessing.RobustScaler()\n",
    "col_names = list(heart.columns)\n",
    "\n",
    "# копируем исходный датасет\n",
    "heart_r = r_scaler.fit_transform(heart)\n",
    "\n",
    "heart_r = pd.DataFrame(heart_r, columns=col_names)\n",
    "\n",
    "# смотрим описательные статистики, ответ 0.816232\n",
    "heart_r.describe()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
