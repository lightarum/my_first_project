{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия о методу наименьших квадратов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  PRICE  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка библиотек\n",
    "import numpy as np # для работы с массивами\n",
    "import pandas as pd # для работы с DataFrame \n",
    "from sklearn import datasets # для импорта данных\n",
    "import seaborn as sns # для визуализации статистических данных\n",
    "import matplotlib.pyplot as plt # для построения графиков\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "\n",
    "# загружаем датасет\n",
    "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'PRICE']\n",
    "boston_data = pd.read_csv('data/housing.csv', header=None, delimiter=r\"\\s+\", names=column_names)\n",
    "boston_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000e+00 6.3200e-03 6.5750e+00]\n",
      " [1.0000e+00 2.7310e-02 6.4210e+00]\n",
      " [1.0000e+00 2.7290e-02 7.1850e+00]\n",
      " ...\n",
      " [1.0000e+00 6.0760e-02 6.9760e+00]\n",
      " [1.0000e+00 1.0959e-01 6.7940e+00]\n",
      " [1.0000e+00 4.7410e-02 6.0300e+00]]\n"
     ]
    }
   ],
   "source": [
    "# составляем матрицу А и вектор целевой переменной\n",
    "CRIM = boston_data['CRIM']\n",
    "RM = boston_data['RM']\n",
    "A = np.column_stack((np.ones(506), CRIM, RM))\n",
    "y = boston_data[['PRICE']]\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 3)\n"
     ]
    }
   ],
   "source": [
    "# проверим размерность\n",
    "print(A.shape)\n",
    "## (506, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-29.24471945]\n",
      " [ -0.26491325]\n",
      " [  8.39106825]]\n"
     ]
    }
   ],
   "source": [
    "# вычислим OLS-оценку для коэффициентов\n",
    "w_hat = np.linalg.inv(A.T@A)@A.T@y\n",
    "print(w_hat.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37.85733519]\n"
     ]
    }
   ],
   "source": [
    "# добавились новые данные:\n",
    "CRIM_new = 0.1\n",
    "RM_new = 8\n",
    "# делаем прогноз типичной стоимости дома\n",
    "PRICE_new = w_hat.iloc[0]+w_hat.iloc[1]*CRIM_new+w_hat.iloc[2]*RM_new\n",
    "print(PRICE_new.values)\n",
    "## [37.85733519]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [[37.85733519]]\n"
     ]
    }
   ],
   "source": [
    "# короткий способ сделать прогноз\n",
    "new=np.array([[1,CRIM_new,RM_new]])\n",
    "print('prediction:', (new@w_hat).values)\n",
    "## prediction: [[37.85733519]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_hat: [[-29.24471945  -0.26491325   8.39106825]]\n",
      "prediction: [[37.85733519]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# создаём модель линейной регрессии\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "\n",
    "#Здесь при создании объекта класса LinearRegression мы указали fit_intercept=False, так как в нашей матрице наблюдений \n",
    "# уже присутствует столбец с единицами для умножения на свободный член . Его повторное добавление не имеет смысла.\n",
    "# вычисляем коэффициенты регрессии ТО ЕСТЬ ИЛИ ИНТЕРСЕПТ ИЛИ БЕЗ ! СТОЛБЕЦ НЕ ДОБАВЛЯТЬ\n",
    "\n",
    "\n",
    "model.fit(A, y)\n",
    "print('w_hat:', model.coef_)\n",
    "new_prediction = model.predict(new)\n",
    "print('prediction:', new_prediction)\n",
    "## w_hat: [[-29.24471945  -0.26491325   8.39106825]]\n",
    "## prediction: [[37.85733519]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [[21.04870738]]\n"
     ]
    }
   ],
   "source": [
    "CRIM_new1 = 0.2\n",
    "RM_new1 = 6\n",
    "\n",
    "# короткий способ сделать прогноз\n",
    "new=np.array([[1,CRIM_new1,RM_new1]])\n",
    "print('prediction:', (new@w_hat).values)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ОСОБЕННОСТИ КЛАССА LINEAR REGRESSION БИБЛИОТЕКИ SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m5\u001b[39m, \u001b[39m1\u001b[39m])\n\u001b[0;32m      8\u001b[0m \u001b[39m# вычислим OLS-оценку для коэффициентов\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m w_hat\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49minv(A\u001b[39m.\u001b[39;49mT\u001b[39m@A\u001b[39;49m)\u001b[39m@A\u001b[39m\u001b[39m.\u001b[39mT\u001b[39m@y\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[39mprint\u001b[39m(w_hat) \n\u001b[0;32m     11\u001b[0m \u001b[39m## LinAlgError: Singular matrix\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36minv\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\linalg\\linalg.py:552\u001b[0m, in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    550\u001b[0m signature \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mD->D\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m isComplexType(t) \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39md->d\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    551\u001b[0m extobj \u001b[39m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[1;32m--> 552\u001b[0m ainv \u001b[39m=\u001b[39m _umath_linalg\u001b[39m.\u001b[39;49minv(a, signature\u001b[39m=\u001b[39;49msignature, extobj\u001b[39m=\u001b[39;49mextobj)\n\u001b[0;32m    553\u001b[0m \u001b[39mreturn\u001b[39;00m wrap(ainv\u001b[39m.\u001b[39mastype(result_t, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\linalg\\linalg.py:89\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[1;32m---> 89\u001b[0m     \u001b[39mraise\u001b[39;00m LinAlgError(\u001b[39m\"\u001b[39m\u001b[39mSingular matrix\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "# создадим вырожденную матрицу А\n",
    "A = np.array([\n",
    "    [1, 1, 1, 1], \n",
    "    [2, 1, 1, 2], \n",
    "    [-2, -1, -1, -2]]\n",
    ").T\n",
    "y = np.array([1, 2, 5, 1])\n",
    "# вычислим OLS-оценку для коэффициентов\n",
    "w_hat=np.linalg.inv(A.T@A)@A.T@y\n",
    "print(w_hat) \n",
    "## LinAlgError: Singular matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_hat: [ 6.   -1.25  1.25]\n"
     ]
    }
   ],
   "source": [
    "# создаём модель линейной регрессии\n",
    "model = LinearRegression(fit_intercept=False)\n",
    "# вычисляем коэффициенты регрессии\n",
    "model.fit(A, y)\n",
    "print('w_hat:', model.coef_)\n",
    "## w_hat: [ 6.   -1.25  1.25] НИКАКОЙ ОШИБКИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6.  , -1.25,  1.25]),\n",
       " array([], dtype=float64),\n",
       " 2,\n",
       " array([4.86435029, 0.58146041, 0.        ]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# классическая OLS-регрессия в numpy с возможностью получения решения даже для вырожденных матриц\n",
    "np.linalg.lstsq(A, y, rcond=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.7\n",
    "\n",
    "A = np.array([\n",
    "    [1, 1, 1, 1],\n",
    "    [1, 1, 0, 2],\n",
    "    [-1, 1, 0, 0],\n",
    "    [0, 2, 0, 2]\n",
    "]).T\n",
    "np.linalg.matrix_rank(A.T@A)\n",
    "## 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## СТАНДАРТИЗАЦИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.92052548]\n",
      " [ 3.9975594 ]\n",
      " [-0.58240212]\n",
      " [-0.09739445]\n",
      " [ 5.07554248]]\n"
     ]
    }
   ],
   "source": [
    "# составляем матрицу наблюдений и вектор целевой переменной\n",
    "A = np.column_stack((np.ones(506), boston_data[['CHAS', 'LSTAT', 'CRIM','RM']]))\n",
    "y = boston_data[['PRICE']]\n",
    "# вычисляем OLS-оценку для коэффициентов без стандартизации\n",
    "w_hat=np.linalg.inv(A.T@A)@A.T@y\n",
    "print(w_hat.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CHAS</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>CRIM</th>\n",
       "      <th>RM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.00</td>\n",
       "      <td>506.00</td>\n",
       "      <td>506.00</td>\n",
       "      <td>506.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.16</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CHAS   LSTAT    CRIM      RM\n",
       "count  506.00  506.00  506.00  506.00\n",
       "mean    -0.00   -0.00   -0.00   -0.00\n",
       "std      0.04    0.04    0.04    0.04\n",
       "min     -0.01   -0.07   -0.02   -0.17\n",
       "25%     -0.01   -0.04   -0.02   -0.03\n",
       "50%     -0.01   -0.01   -0.02   -0.00\n",
       "75%     -0.01    0.03    0.00    0.02\n",
       "max      0.16    0.16    0.44    0.16"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# составляем матрицу наблюдений без дополнительного столбца из единиц\n",
    "A = boston_data[['CHAS', 'LSTAT', 'CRIM','RM']]\n",
    "y = boston_data[['PRICE']]\n",
    "# стандартизируем векторы в столбцах матрицы A\n",
    "A_cent = A - A.mean()\n",
    "A_st = A_cent/np.linalg.norm(A_cent, axis=0) #обязательно указать axis=0\n",
    "A_st.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(np.linalg.norm(A_st, axis=0))\n",
    "## [1. 1. 1. 1.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# стандартизируем вектор целевой переменной\n",
    "y_cent = y - y.mean()\n",
    "y_st = y_cent/np.linalg.norm(y_cent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11039956]\n",
      " [-0.45220423]\n",
      " [-0.09108766]\n",
      " [ 0.38774848]]\n"
     ]
    }
   ],
   "source": [
    "# вычислим OLS-оценку для стандартизированных коэффициентов\n",
    "w_hat_st=np.linalg.inv(A_st.T@A_st)@A_st.T@y_st\n",
    "print(w_hat_st.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.70710678, -0.70710678])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.3\n",
    "\n",
    "A = np.array([12,8]).T\n",
    "A_cent = A - A.mean()\n",
    "A_st = A_cent/np.linalg.norm(A_cent, axis=0)\n",
    "A_st"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## МАТРИЦА КОРРЕЛЯЦИЙ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.18898224],\n",
       "       [-0.18898224,  1.        ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_1 = np.array([1, 2, 6])\n",
    "x_2 = np.array([3000, 1000, 2000])\n",
    "np.corrcoef(x_1, x_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05\n"
     ]
    }
   ],
   "source": [
    "# 4.7\n",
    "\n",
    "x_3 = np.array([5, 1, 2])\n",
    "x_4 = np.array([4, 2, 8])\n",
    "np.corrcoef(x_3, x_4)\n",
    "\n",
    "print('{:.2f}'.format(np.corrcoef(x_3, x_4)[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank: 3\n",
      "Determinant: 0.0000005\n",
      "[[1.         0.99925473 0.99983661]\n",
      " [0.99925473 1.         0.99906626]\n",
      " [0.99983661 0.99906626 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# 4.8 \n",
    "\n",
    "x_1 = np.array([5.1, 1.8, 2.1, 10.3, 12.1, 12.6])\n",
    "x_2 = np.array([10.2, 3.7, 4.1, 20.5, 24.2, 24.1])\n",
    "x_3 = np.array([2.5, 0.9, 1.1, 5.1, 6.1, 6.3])\n",
    "\n",
    "C = np.corrcoef([x_1, x_2, x_3])\n",
    "rk_c = np.linalg.matrix_rank(C)\n",
    "rk_c\n",
    "\n",
    "print('Rank:', np.linalg.matrix_rank(C))\n",
    "print('Determinant: {:.7f}'.format(np.linalg.det(C)))\n",
    "print(C)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В PANDAS это corr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Полиномиальная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.4        0.46666667 0.13333333]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [1, 1, 1, 1],\n",
    "    [1, 3, -2, 1],\n",
    "    [1, 9, 4, 1]\n",
    "]).T\n",
    "y = np.array([4, 5, 2, 2])\n",
    "w_hat = np.linalg.inv(A.T@A)@A.T@y\n",
    "print(w_hat) \n",
    "# [2.4        0.46666667 0.13333333]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.25799015  2.37672337 -0.1322068  -0.10208147 -0.26501791  0.29722471]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([\n",
    "    [1, 1, 1, 1, 1, 1, 1],\n",
    "    [1, 3, -2, 1, 5, 13, 1],\n",
    "    [3, 4, 5, -2, 4, 11, 3],\n",
    "    [1, 9, 4, 1, 25, 169, 1],\n",
    "    [3, 12, -10, -2, 20, 143, 3],\n",
    "    [9, 16, 25, 4, 16, 121, 9]\n",
    "    \n",
    "]).T\n",
    "y = np.array([4, 5, 2, 2, 6, 8, -1])\n",
    "w_hat = np.linalg.inv(A.T@A)@A.T@y\n",
    "print(w_hat)\n",
    "## [-2.25799015  2.37672337 -0.1322068  -0.10208147 -0.26501791  0.29722471]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  3  4]\n",
      " [ 3  4  5]\n",
      " [-2  5  2]\n",
      " [ 1 -2  2]\n",
      " [ 5  4  6]\n",
      " [13 11  8]\n",
      " [ 1  3 -1]]\n"
     ]
    }
   ],
   "source": [
    "# столбец тз 1 НЕ ДОБАВЛЯЕМ,это автоматич сделет полиномиальнае регрессия\n",
    "\n",
    "A = np.array([\n",
    "    [1, 3, -2, 1, 5, 13, 1],\n",
    "    [3, 4, 5, -2, 4, 11, 3],\n",
    "    [4, 5, 2, 2, 6, 8, -1],\n",
    "]).T\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(degree=2, include_bias=True) # указав при инициализации степень полинома равной 2\n",
    "\n",
    "# нужна генерация столбца из 1 (параметр include_bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3      4      5      6      7     8     9\n",
       "0  1.0   1.0   3.0  4.0    1.0    3.0    4.0    9.0  12.0  16.0\n",
       "1  1.0   3.0   4.0  5.0    9.0   12.0   15.0   16.0  20.0  25.0\n",
       "2  1.0  -2.0   5.0  2.0    4.0  -10.0   -4.0   25.0  10.0   4.0\n",
       "3  1.0   1.0  -2.0  2.0    1.0   -2.0    2.0    4.0  -4.0   4.0\n",
       "4  1.0   5.0   4.0  6.0   25.0   20.0   30.0   16.0  24.0  36.0\n",
       "5  1.0  13.0  11.0  8.0  169.0  143.0  104.0  121.0  88.0  64.0\n",
       "6  1.0   1.0   3.0 -1.0    1.0    3.0   -1.0    9.0  -3.0   1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A_poly = poly.fit_transform(A)\n",
    "display(pd.DataFrame(A_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial_regression(X, y, k):\n",
    "    poly = PolynomialFeatures(degree=k, include_bias=True)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    w_hat = np.linalg.inv(X_poly.T@X_poly)@X_poly.T@y\n",
    "    y_pred = X_poly @ w_hat\n",
    "    return X_poly, y_pred, w_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = boston_data[['LSTAT', 'PTRATIO', 'RM', 'CRIM']]\n",
    "y = boston_data[['PRICE']]\n",
    " \n",
    "A_poly, y_pred, w_hat = polynomial_regression(A, y, 1)\n",
    "A_poly2, y_pred2, w_hat2 = polynomial_regression(A, y, 2)\n",
    "A_poly3, y_pred3, w_hat3 = polynomial_regression(A, y, 3)\n",
    "A_poly4, y_pred4, w_hat4 = polynomial_regression(A, y, 4)\n",
    "A_poly5, y_pred5, w_hat5 = polynomial_regression(A, y, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE для полинома 1-й степени 18.20%\n",
      "MAPE для полинома 2-й степени  13.41%\n",
      "MAPE для полинома 3-й степени  12.93%\n",
      "MAPE для полинома 4-й степени  10.73%\n",
      "MAPE для полинома 5-й степени  251.76%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    " \n",
    "print('MAPE для полинома 1-й степени {:.2f}%'.format(mean_absolute_percentage_error(y, y_pred)*100))\n",
    "print('MAPE для полинома 2-й степени  {:.2f}%'.format(mean_absolute_percentage_error(y, y_pred2)*100))\n",
    "print('MAPE для полинома 3-й степени  {:.2f}%'.format(mean_absolute_percentage_error(y, y_pred3)*100))\n",
    "print('MAPE для полинома 4-й степени  {:.2f}%'.format(mean_absolute_percentage_error(y, y_pred4)*100))\n",
    "print('MAPE для полинома 5-й степени  {:.2f}%'.format(mean_absolute_percentage_error(y, y_pred5)*100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выясняем, почему у полинома 5 степени такое огромное значение mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>126.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1149.316675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>32458.097510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-162614.598984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.774516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.700405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>320362.757163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               PRICE\n",
       "count     126.000000\n",
       "mean     1149.316675\n",
       "std     32458.097510\n",
       "min   -162614.598984\n",
       "25%        -0.774516\n",
       "50%        -0.000306\n",
       "75%         1.700405\n",
       "max    320362.757163"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(w_hat5).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранг корреляционной матрицы: 110\n",
      "Количество факторов: 125\n"
     ]
    }
   ],
   "source": [
    "# считаем матрицу корреляций (без столбца из единиц)\n",
    "C = pd.DataFrame(A_poly5[:, 1:]).corr()\n",
    "# считаем ранг корреляционной матрицы\n",
    "print('Ранг корреляционной матрицы:', np.linalg.matrix_rank(C))\n",
    "# считаем количество факторов (не включая столбец из единиц)\n",
    "print('Количество факторов:', A_poly5[:, 1:].shape[1])\n",
    "# Ранг корреляционной матрицы: 110\n",
    "# Количество факторов: 125"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы нашли корень проблемы: ранг корреляционной матрицы — 110, в то время как общее количество факторов (не считая единичного столбца) — 125, то есть ранг корреляционной матрицы не максимален. Это значит, что в корреляционной матрице присутствуют единичные корреляции, а в исходной матрице — линейно зависимые столбцы.\n",
    "\n",
    "Как так вышло? На самом деле всё очень просто: в процессе перемножения каких-то из столбцов при создании полинома пятой степени получился такой полиномиальный фактор, который линейно выражается через другие факторы.\n",
    "\n",
    "В результате при вычислении обратной матрицы  у нас получилось деление на число, близкое к 0, а элементы обратной матрицы получились просто огромными. Отсюда и появились явно неверные степени коэффициентов, которые дают далёкий от действительности прогноз, что приводит к отрицательной метрике."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ранг корреляционной матрицы: 69\n",
      "Количество факторов: 69\n"
     ]
    }
   ],
   "source": [
    "# считаем матрицу корреляций (без столбца из единиц)\n",
    "C = pd.DataFrame(A_poly4[:, 1:]).corr()\n",
    "# считаем ранг корреляционной матрицы\n",
    "print('Ранг корреляционной матрицы:', np.linalg.matrix_rank(C))\n",
    "# считаем количество факторов (не включая столбец из единиц)\n",
    "print('Количество факторов:', A_poly4[:, 1:].shape[1])\n",
    "## Ранг корреляционной матрицы: 69\n",
    "## Количество факторов: 69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-50.838140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>886.825438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-6920.881600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.187939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-0.000799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.322193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2304.997953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             PRICE\n",
       "count    70.000000\n",
       "mean    -50.838140\n",
       "std     886.825438\n",
       "min   -6920.881600\n",
       "25%      -0.187939\n",
       "50%      -0.000799\n",
       "75%       0.322193\n",
       "max    2304.997953"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(w_hat4).describe()) # ранг матрицы максимален 69,поэтому коэффициенты нормальные"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Строим то же,но не с numpy а со sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE для полинома степени 1 — 18.20%, СКО — 2\n",
      "MAPE для полинома степени 2 — 13.41%, СКО — 5\n",
      "MAPE для полинома степени 3 — 12.93%, СКО — 9\n",
      "MAPE для полинома степени 4 — 10.74%, СКО — 304\n",
      "MAPE для полинома степени 5 — 9.02%, СКО — 17055\n"
     ]
    }
   ],
   "source": [
    "def polynomial_regression_sk(X, y, k):\n",
    "    poly = PolynomialFeatures(degree=k, include_bias=False)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    lr = LinearRegression().fit(X_poly, y)\n",
    "    y_pred = lr.predict(X_poly)\n",
    "    return X_poly, y_pred, lr.coef_\n",
    "\n",
    "A = boston_data[['LSTAT', 'PTRATIO', 'RM', 'CRIM']]\n",
    "y = boston_data[['PRICE']]\n",
    "\n",
    "for k in range(1, 6):\n",
    "    A_poly, y_pred, w_hat = polynomial_regression_sk(A, y, k)\n",
    "    print(\n",
    "        \"MAPE для полинома степени {} — {:.2f}%, СКО — {:.0f}\".format(\n",
    "            k, mean_absolute_percentage_error(y, y_pred)*100, w_hat.std()\n",
    "        )\n",
    "\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему полином 5 степент посчитался????<br>\n",
    "\n",
    "А самом деле с этим «заклинанием» из библиотеки sklearn мы уже знакомились в предыдущих юнитах. Секрет в том, что в sklearn для построения линейной регрессии используется не сама матрица наблюдений , а её сингулярное разложение, которое гарантированно является невырожденным — из него исключаются линейно зависимые факторы. Таким образом, даже несмотря на немаксимальный ранг корреляционной матрицы, построить полином пятой степени всегда получится."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.1  2.5 -0. ]\n"
     ]
    }
   ],
   "source": [
    "# ЗАДАЧИ 6.4\n",
    "\n",
    "A = np.array([\n",
    "    [1, 1, 1, 1],\n",
    "    [1, 3, -2, 9],\n",
    "    [1, 9, 4, 81]\n",
    "]).T\n",
    "y = np.array([3, 7, -5, 21])\n",
    "\n",
    "\n",
    "print(np.round(np.linalg.inv(A.T@A)@A.T@y, 1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Регуляризация"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки качества модели будем использовать кросс-валидацию и сравнивать среднее значение метрики на тренировочных и валидационных фолдах. Кросс-валидацию организуем с помощью функции cross_validate из модуля model_selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE на тренировочных фолдах: 12.64 %\n",
      "MAPE на валидационных фолдах: 24.16 %\n"
     ]
    }
   ],
   "source": [
    "# выделяем интересующие нас факторы\n",
    "X = boston_data[['LSTAT', 'PTRATIO', 'RM','CRIM']]\n",
    "y = boston_data[['PRICE']]\n",
    " \n",
    "# добавляем полиномиальные признаки\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X = poly.fit_transform(X)\n",
    " \n",
    "# создаём модель линейной регрессии\n",
    "lr = LinearRegression()\n",
    " \n",
    "# оцениваем качество модели на кросс-валидации, метрика — MAPE\n",
    "cv_results = cross_validate(lr, X, y, scoring='neg_mean_absolute_percentage_error', cv=5, return_train_score=True)\n",
    "print('MAPE на тренировочных фолдах: {:.2f} %'.format(-cv_results['train_score'].mean()* 100))\n",
    "print('MAPE на валидационных фолдах: {:.2f} %'.format(-cv_results['test_score'].mean() * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как с этим справиться, мы тоже уже знаем.\n",
    "\n",
    "Можно попробовать понизить сложность модели (снизить степень полинома). Но до какой степени? Можно постепенно перебирать степень полинома до тех пор, пока не получим адекватные результаты, но, согласитесь, процедура не очень приятная.\n",
    "Можно воспользоваться методами регуляризации."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* предотвратить переобучение модели;\n",
    "* включить в функцию потерь штраф за переобучение;\n",
    "* обеспечить существование обратной матрицы ;\n",
    "* не допустить огромных коэффициентов модели."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2-РЕГУЛЯРИЗАЦИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "Singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m4\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m4\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m7\u001b[39m])\n\u001b[0;32m      9\u001b[0m \u001b[39m# получаем оценку коэффициентов регрессии по МНК\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m w_hat \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mlinalg\u001b[39m.\u001b[39;49minv(A\u001b[39m.\u001b[39;49mT\u001b[39m@A\u001b[39;49m)\u001b[39m@A\u001b[39m\u001b[39m.\u001b[39mT\u001b[39m@y\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(w_hat) \n\u001b[0;32m     12\u001b[0m \u001b[39m## LinAlgError: Singular matrix\u001b[39;00m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36minv\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\linalg\\linalg.py:552\u001b[0m, in \u001b[0;36minv\u001b[1;34m(a)\u001b[0m\n\u001b[0;32m    550\u001b[0m signature \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mD->D\u001b[39m\u001b[39m'\u001b[39m \u001b[39mif\u001b[39;00m isComplexType(t) \u001b[39melse\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39md->d\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    551\u001b[0m extobj \u001b[39m=\u001b[39m get_linalg_error_extobj(_raise_linalgerror_singular)\n\u001b[1;32m--> 552\u001b[0m ainv \u001b[39m=\u001b[39m _umath_linalg\u001b[39m.\u001b[39;49minv(a, signature\u001b[39m=\u001b[39;49msignature, extobj\u001b[39m=\u001b[39;49mextobj)\n\u001b[0;32m    553\u001b[0m \u001b[39mreturn\u001b[39;00m wrap(ainv\u001b[39m.\u001b[39mastype(result_t, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m))\n",
      "File \u001b[1;32mc:\\Users\\sveta\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\linalg\\linalg.py:89\u001b[0m, in \u001b[0;36m_raise_linalgerror_singular\u001b[1;34m(err, flag)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_raise_linalgerror_singular\u001b[39m(err, flag):\n\u001b[1;32m---> 89\u001b[0m     \u001b[39mraise\u001b[39;00m LinAlgError(\u001b[39m\"\u001b[39m\u001b[39mSingular matrix\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mLinAlgError\u001b[0m: Singular matrix"
     ]
    }
   ],
   "source": [
    "# матрица наблюдений (включая столбец единиц)\n",
    "A = np.array([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [1, 0, -3, 2, 4],\n",
    "    [2, 0, -6, 4, 8]\n",
    "]).T\n",
    "# вектор целевого признака\n",
    "y = np.array([4, 3, -4, 2, 7])\n",
    "# получаем оценку коэффициентов регрессии по МНК\n",
    "w_hat = np.linalg.inv(A.T@A)@A.T@y\n",
    "print(w_hat) \n",
    "## LinAlgError: Singular matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6122449  0.29387755 0.5877551 ]\n"
     ]
    }
   ],
   "source": [
    "# матрица наблюдений (включая столбец единиц)\n",
    "A = np.array([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [1, 0, -3, 2, 4],\n",
    "    [2, 0, -6, 4, 8]\n",
    "]).T\n",
    "# вектор целевого признака\n",
    "y = np.array([4, 3, -4, 2, 7])\n",
    "# единичная матрица\n",
    "E = np.eye(3)\n",
    "# коэффициент регуляризации \n",
    "alpha = 5\n",
    "# получаем оценку коэффициентов регрессии по МНК с регуляризацией Тихонова\n",
    "w_hat_ridge = np.linalg.inv(A.T@A+alpha*E)@A.T@y\n",
    "print(w_hat_ridge) \n",
    "## [0.6122449  0.29387755 0.5877551 ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, мы посмотрели, как работает аналитическое решение -регуляризации. Однако в реализации sklearn для решения этой задачи поддерживается сразу несколько методов — как численных (координатный спуск, градиентный спуск или LBFGS), так и аналитических (классическая регуляризация Тихонова или она же через SVD-разложение). По умолчанию метод выбирается автоматически. На простых данных все методы будут показывать примерно одинаковые результаты при одном и том же значении коэффициента регуляризации, однако на реальных данных, когда данные не стандартизированы и присутствует сильная мультиколлинеарность между факторами, результат работы каждого из методов решения задачи оптимизации может значительно отличаться. Имейте это в виду при построении модели. Подробнее о методах вы можете прочитать в документации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6122449  0.29387755 0.5877551 ]\n"
     ]
    }
   ],
   "source": [
    "# матрица наблюдений (включая столбец единиц)\n",
    "A = np.array([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [1, 0, -3, 2, 4],\n",
    "    [2, 0, -6, 4, 8]\n",
    "]).T\n",
    "# вектор целевого признака\n",
    "y = np.array([4, 3, -4, 2, 7])\n",
    "# получаем оценку коэффициентов регрессии по МНК с регуляризацией Тихонова\n",
    "ridge = Ridge(alpha=5, fit_intercept=False) #аранее заложили в матрицу  столбец из единиц, \n",
    "#то, чтобы получить корректное решение, параметр fit_intercept следует установить в значение False.\n",
    "ridge.fit(A, y)\n",
    "print(ridge.coef_) \n",
    "## [0.6122449  0.29387755 0.5877551 ]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Сразу отметим, что для успешной сходимости численных методов оптимизации, которые используются для решения задачи условной оптимизации, необходима стандартизация (нормализация) исходных данных, которая не требовалась для аналитического МНК в классической линейной регрессии (LinearRegression).\n",
    "\n",
    " StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE на тренировочных фолдах: 12.54 %\n",
      "MAPE на валидационных фолдах: 17.02 %\n"
     ]
    }
   ],
   "source": [
    "# выделяем интересующие нас факторы\n",
    "X = boston_data[['LSTAT', 'PTRATIO', 'RM','CRIM']]\n",
    "y = boston_data[['PRICE']]\n",
    "# инициализируем стандартизатор StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# подгоняем параметры стандартизатора (вычисляем среднее и СКО)\n",
    "X = scaler.fit_transform(X)\n",
    "# добавляем полиномиальные признаки\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X = poly.fit_transform(X)\n",
    "# создаём модель линейной регрессии c L2-регуляризацией\n",
    "ridge = Ridge(alpha=20, solver='svd')\n",
    "# оцениваем качество модели на кросс-валидации\n",
    "cv_results = cross_validate(ridge, X, y, scoring='neg_mean_absolute_percentage_error', cv=5, return_train_score=True)\n",
    "print('MAPE на тренировочных фолдах: {:.2f} %'.format(-cv_results['train_score'].mean()* 100))\n",
    "print('MAPE на валидационных фолдах: {:.2f} %'.format(-cv_results['test_score'].mean() * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам удалось уменьшить ошибку (MAPE) на валидационных фолдах кросс-валидации с 24.16% до 17.02% и сократить разницу в метриках, тем самым уменьшив разброс ответов модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.09 -1.71  1.91  0.73]\n"
     ]
    }
   ],
   "source": [
    "# 7.4\n",
    "\n",
    "A = np.array([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [5, 9, 4, 3, 5],\n",
    "    [15, 18, 18, 19, 19],\n",
    "    [7, 6, 7, 7, 7]\n",
    "]).T\n",
    "y = np.array([24, 22, 35, 33, 36])\n",
    "E = np.eye(4)\n",
    "\n",
    "alpha = 1\n",
    "# получаем оценку коэффициентов регрессии по МНК с регуляризацией Тихонова\n",
    "w_hat_ridge = np.linalg.inv(A.T@A+alpha*E)@A.T@y\n",
    "print(np.round(w_hat_ridge, 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 - РЕГУЛЯРИЗАЦИЯ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.14925373 0.         0.71921642]\n"
     ]
    }
   ],
   "source": [
    "# матрица наблюдений (включая столбец единиц)\n",
    "A = np.array([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [1, 0, -3, 2, 4],\n",
    "    [2, 0, -6, 4, 8]\n",
    "]).T\n",
    "# вектор целевого признака\n",
    "y = np.array([4, 3, -4, 2, 7])\n",
    "# получаем оценку коэффициентов регрессии с помощью L1-регуляризации\n",
    "lasso = Lasso(alpha=0.1, fit_intercept=False)\n",
    "lasso.fit(A, y)\n",
    "print(lasso.coef_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Сразу обращаем внимание, что, в отличие от регуляризации Тихонова, -регуляризация «занулила» коэффициент, стоящий при факторе . Это произошло не случайно, так как это особенность данного метода. Как говорится, «не баг, а фича», причём очень важная. Коэффициенты, стоящие при коллинеарных или высококоррелированных факторах, зануляются. Также чем выше коэффициент регуляризации, тем больше вероятность того, что коррелированные или малозначащие факторы будут исключены из модели. Чуть позже мы рассмотрим геометрическую интерпретацию и поймём, почему так происходит."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE на тренировочных фолдах: 12.44 %\n",
      "MAPE на валидационных фолдах: 16.44 %\n"
     ]
    }
   ],
   "source": [
    "# выделяем интересующие нас факторы\n",
    "X = boston_data[['LSTAT', 'PTRATIO', 'RM','CRIM']]\n",
    "y = boston_data[['PRICE']]\n",
    "\n",
    "# инициализируем стандартизатор StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# подгоняем параметры стандартизатора (вычисляем среднее и СКО)\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# добавляем полиномиальные признаки\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X = poly.fit_transform(X)\n",
    "\n",
    "# создаём модель линейной регрессии c L1-регуляризацией\n",
    "lasso = Lasso(alpha=0.1, max_iter=10000)\n",
    "\n",
    "# оцениваем качество модели на кросс-валидации\n",
    "cv_results = cross_validate(lasso, X, y, scoring='neg_mean_absolute_percentage_error', cv=5, return_train_score=True)\n",
    "print('MAPE на тренировочных фолдах: {:.2f} %'.format(-cv_results['train_score'].mean()* 100))\n",
    "print('MAPE на валидационных фолдах: {:.2f} %'.format(-cv_results['test_score'].mean() * 100))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ELASTIC-NET"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые рекомендации от разработчиков ElasticNet:\n",
    "\n",
    "Использование параметра l1_ratio <0.01 приводит к нестабильным результатам.\n",
    "Вместо использования ElasticNet с alpha=0 лучше используйте LinearRegression, так как там применяется аналитическое решение, которое позволяет получать более точные решения, чем численный координатный спуск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.13492457 0.19525842 0.6237965 ]\n"
     ]
    }
   ],
   "source": [
    "# матрица наблюдений (включая столбец единиц)\n",
    "A = np.array([\n",
    "    [1, 1, 1, 1, 1],\n",
    "    [1, 0, -3, 2, 4],\n",
    "    [2, 0, -6, 4, 8]\n",
    "]).T\n",
    "# вектор целевого признака\n",
    "y = np.array([4, 3, -4, 2, 7])\n",
    "# получаем оценку коэффициентов регрессии \n",
    "elasticnet = ElasticNet(alpha=0.1, l1_ratio=0.2, fit_intercept=False)\n",
    "elasticnet.fit(A, y)\n",
    "print(elasticnet.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.14379753 0.         0.71993025]\n"
     ]
    }
   ],
   "source": [
    "# получаем оценку коэффициентов регрессии\n",
    "elasticnet = ElasticNet(alpha=0.1, l1_ratio=0.7, fit_intercept=False)\n",
    "elasticnet.fit(A, y)\n",
    "print(elasticnet.coef_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "братим внимание, что произошло зануление коэффициентов. Это неспроста, так как мы понизили влияние l2-регуляризации и одновременно повысили влияние l1-регуляризации, которая, как мы уже знаем, приводит к исключению линейно зависимых факторов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.14925373 0.         0.71921642]\n"
     ]
    }
   ],
   "source": [
    "# получаем оценку коэффициентов регрессии\n",
    "elasticnet = ElasticNet(alpha=0.1, l1_ratio=1, fit_intercept=False)\n",
    "elasticnet.fit(A, y)\n",
    "print(elasticnet.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAPE на тренировочных фолдах: 12.65 %\n",
      "MAPE на валидационных фолдах: 15.70 %\n"
     ]
    }
   ],
   "source": [
    "# выделяем интересующие нас факторы\n",
    "X = boston_data[['LSTAT', 'PTRATIO', 'RM','CRIM']]\n",
    "y = boston_data[['PRICE']]\n",
    "# инициализируем стандартизатор StandardScaler\n",
    "scaler = StandardScaler()\n",
    "# подгоняем параметры стандартизатора (вычисляем среднее и СКО)\n",
    "X = scaler.fit_transform(X)\n",
    "# добавляем полиномиальные признаки\n",
    "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
    "X = poly.fit_transform(X)\n",
    "# создаём модель линейной регрессии c L1- и L2-регуляризациями\n",
    "lasso = ElasticNet(alpha=0.1, l1_ratio=0.5, max_iter=10000)\n",
    "# оцениваем качество модели на кросс-валидации\n",
    "cv_results = cross_validate(lasso, X, y, scoring='neg_mean_absolute_percentage_error', cv=5, return_train_score=True)\n",
    "print('MAPE на тренировочных фолдах: {:.2f} %'.format(-cv_results['train_score'].mean()* 100))\n",
    "print('MAPE на валидационных фолдах: {:.2f} %'.format(-cv_results['test_score'].mean() * 100)) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На практике при использовании моделей с регуляризацией стоит подбирать значения коэффициентов регуляризации с помощью методов подбора гиперпараметров"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
